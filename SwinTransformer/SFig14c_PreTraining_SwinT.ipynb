{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Pre-training of SwinTransformer\n","\n","Initial training, validation, and testing of a Transformer model for the task of classifying the strain present in images from our all-strain *Proteus mirabilis* dataset. The optimal model obtained was further fine-tuned in a separate notebook for the new task of classifying the relative IPTG concentraion (low vs. high) of *P. mirabilis* pLac-*cheW* images. The performance of the fine-tuned model was later evaluated based on its ability to accurately classify test images of pLac-*cheW* colonies grown at temperatures previously unseen during model training and evaluation.     \n","\n","We implement the SwinTransformerTiny224, the shallowest of the SwinTransformer classification models, as originally presented by Liu et al. 2021 and made readily available in Keras (TensorFlow) by Shkarupa<sup>1,2</sup>.\n","\n","[1] Liu, Z., Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo. *Swin transformer: Hierarchical vision transformer using shifted windows*. in *Proceedings of the IEEE/CVF International Conference on Computer Vision*. 2021.\n","\n","[2] Shkarupa, A. *tfswin*. 2022; Available from: https://github.com/shkarupa-alex/tfswin."],"metadata":{"id":"N3CQ8nS7pHGX"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"ZqbuzVdFSrtR"}},{"cell_type":"code","source":["! pip install tfswin"],"metadata":{"id":"ulkoRUUrXmEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsP1scqzWewe"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import numpy as np\n","import shutil\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","import math\n","import inspect\n","from collections import Counter\n","import pickle \n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import preprocessing, layers, models, callbacks\n","from tensorflow.keras.preprocessing import image \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tfswin import SwinTransformerTiny224, preprocess_input  "]},{"cell_type":"code","source":["# mount my Google Drive where datasets are stored\n","drive.mount('/content/gdrive')"],"metadata":{"id":"iy8iXk986Gju"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"9jLz3jty34DE"}},{"cell_type":"code","source":["# Set the path to umbrella directory\n","drive_classification_dir = '/content/gdrive/MyDrive/Classification_mirabilis/'\n","\n","# Set the path to all image datasets \n","img_datasets_dir = drive_classification_dir + 'img_datasets/'\n","\n","# Set the path to the specific dataset to use\n","this_dataset_name = 'img_dataset_curated_split'\n","this_dataset_dir = img_datasets_dir + this_dataset_name + '/'"],"metadata":{"id":"Ktjz-sxz3zYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Name the model run & create folders for storing results\n","run_name = 'SwinTransformerTiny224_curateddataset_pretr_finetu_aug'\n","run_dir = drive_classification_dir + run_name\n","\n","saved_models_dir = os.path.join(run_dir,'saved_models')\n","histories_dir = os.path.join(run_dir,'histories')\n","CMs_dir = os.path.join(run_dir,'confusion_matrices')\n","\n","all_run_dirs = [run_dir, saved_models_dir, histories_dir, CMs_dir]\n","for run_sub_dir in all_run_dirs:\n","  if not(os.path.isdir(run_sub_dir)):\n","    os.mkdir(run_sub_dir)"],"metadata":{"id":"vmzl9ats5q6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print dataset info\n","subsets = os.listdir(this_dataset_dir)\n","for sub in subsets:\n","  print(f\"-----{sub}-----\")\n","  sub_path = this_dataset_dir + sub\n","  class_list = os.listdir(sub_path)\n","  for cls in class_list:\n","    cls_path = sub_path + '/' + cls\n","    img_list = os.listdir(cls_path)\n","    num_imgs = len(img_list)\n","    print(f\"{cls}: {num_imgs} images total\")"],"metadata":{"id":"MzWztiBJ5xVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First figure out the img size we should use, \n","# based on the default value used in this specific SwinTransformer\n","size_arg = str(inspect.signature(SwinTransformerTiny224).parameters['pretrain_size'])\n","IMG_SIZE = int(size_arg.split('=')[1])\n","print(IMG_SIZE)"],"metadata":{"id":"J_b68YbUt3Pk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ImageDataGenerator \n","# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n","\n","TRAIN_BATCH_SIZE = 4\n","VAL_BATCH_SIZE = 4\n","TEST_BATCH_SIZE = 1\n","\n","train_dir = this_dataset_dir + 'train'\n","val_dir = this_dataset_dir + 'val'\n","test_dir = this_dataset_dir + 'test'\n","\n","datagen = ImageDataGenerator()\n","\n","train_generator = datagen.flow_from_directory(train_dir,\n","                                              class_mode = 'sparse', # either 'sparse' or 'categorical' is fine\n","                                              target_size=(IMG_SIZE, IMG_SIZE),\n","                                              interpolation = 'bicubic', # SwinTransformerTiny224 is sensitive to interpolation method\n","                                              batch_size=TRAIN_BATCH_SIZE,\n","                                              shuffle=True,\n","                                              seed=123,)\n","\n","val_generator = datagen.flow_from_directory(val_dir,\n","                                            class_mode = 'sparse', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=VAL_BATCH_SIZE,\n","                                            shuffle=False,\n","                                            seed=123,)\n","\n","test_generator = datagen.flow_from_directory(test_dir,\n","                                            class_mode = 'sparse', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=TEST_BATCH_SIZE,\n","                                            shuffle=False,\n","                                            seed=123,)"],"metadata":{"id":"mbRdK0mS6Q3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify all possible classes\n","train_class_names = train_generator.class_indices\n","print(train_class_names)\n","val_class_names = val_generator.class_indices\n","print(val_class_names)\n","test_class_names = test_generator.class_indices\n","print(test_class_names)"],"metadata":{"id":"Yb1yEUwq6Thm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# All subsets have same class names & order\n","class_names = train_class_names"],"metadata":{"id":"0VadhRFM6Vm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confirm shapes of batches imgs & labels\n","for image_batch, labels_batch in train_generator:\n","  print(image_batch.shape)\n","  print(labels_batch)\n","  print(labels_batch.shape) # (batch_size, 6) if categorical, (batch_size) if sparse\n","  break"],"metadata":{"id":"I37KxdjK6XAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Determine class counts in each data subset\n","train_counter = Counter(train_generator.classes)    \n","print(train_counter)     \n","val_counter = Counter(val_generator.classes)    \n","print(val_counter)    \n","test_counter = Counter(test_generator.classes)    \n","print(test_counter)    "],"metadata":{"id":"rP1LMQe36ZBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# B/c the classes are imbalanced, compute class weights for training \n","max_val = float(max(train_counter.values()))    \n","print(max_val)                      \n","class_weights = {class_id : max_val/num_images for class_id, num_images in train_counter.items()}  \n","print(class_weights)"],"metadata":{"id":"OYzUSuYY6aXR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model(s): \n","- configuration\n","- training, validtion, & testing"],"metadata":{"id":"57j-wPxn6geS"}},{"cell_type":"code","source":["# Some hyperparamters\n","LR = 1e-5 # learning rate\n","EPSILON = 1e-8"],"metadata":{"id":"BTgVoBO2r6tW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Potential additional on-the-fly augmentations\n","augs_on_the_fly = tf.keras.Sequential([\n","    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',input_shape=(IMG_SIZE,IMG_SIZE,3)),\n","    tf.keras.layers.experimental.preprocessing.RandomZoom((-0.1, -0.02)), # neg for zoom in by random amnt in range [+2%, +10%]\n","    tf.keras.layers.experimental.preprocessing.RandomContrast(0.4),\n","    tf.keras.layers.experimental.preprocessing.RandomRotation((-0.01, 0.01),fill_mode='reflect'),\n","    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=(-0, 0),width_factor=(-0.1, 0.1),fill_mode='reflect')],\n","    name='on_fly_augs')"],"metadata":{"id":"74z326OfU3WW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for building model\n","# finetune='partial','full','none' \n","\n","def build_swintransformer(pretrained=False, finetune='full', data_augmentation=False):\n","  \n","  # first reset all layers\n","  inputs = None\n","  preproces = None\n","  swin_model = None\n","  classification_head = None\n","\n","  # define input shape\n","  inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n","\n","  # optional on-the-fly training augs\n","  if data_augmentation:\n","    x = augs_on_the_fly(inputs)\n","  else:\n","    x = inputs\n","\n","  # preprocess layer\n","  preproces = tf.keras.Sequential([tf.keras.layers.Lambda(preprocess_input)],\n","                                  name='preprocess')\n","\n","  # swin\n","  swin_model = SwinTransformerTiny224(weights=('imagenet' if pretrained else None),\n","                                      include_top=False)\n","  if finetune == 'full':\n","    swin_model.trainable = True\n","  elif finetune == 'none': \n","    swin_model.trainable = False\n","  elif finetune == 'partial':     \n","    # Let's take a look to see how many layers are in the base model\n","    print(\"Number of layers in the base swin model: \", len(swin_model.layers))\n","    # Fine-tune from this layer onwards\n","    fine_tune_at = len(swin_model.layers) // 3\n","    # Freeze all the layers before the `fine_tune_at` layer\n","    for layer in swin_model.layers[:fine_tune_at]:\n","      layer.trainable = False\n","\n","  # classification head\n","  classification_head = tf.keras.Sequential([\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(len(class_names), activation='softmax'),\n","        ],name='class_head')\n","  \n","  # put it all together\n","  x = preproces(x)\n","  x = swin_model(x, training=pretrained)\n","  outputs = classification_head(x)\n","  model = tf.keras.Model(inputs, outputs)\n","\n","  # compile model\n","  model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LR, epsilon=EPSILON),\n","                loss='sparse_categorical_crossentropy', \n","                metrics=['sparse_categorical_accuracy', \n","                         tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name=\"sparse_top_3_categorical_accuracy\")\n","                         ],\n","               )\n","\n","  return model"],"metadata":{"id":"0nC-wGYYl16g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the model versions to try\n","try_models = {\n","    'baseline': build_swintransformer(pretrained=False, finetune='full', data_augmentation=False),\n","    'baseline_aug': build_swintransformer(pretrained=False, finetune='full', data_augmentation=True),\n","    'pretr': build_swintransformer(pretrained=True, finetune='full', data_augmentation=False),\n","    'pretr_aug': build_swintransformer(pretrained=True, finetune='full', data_augmentation=True),\n","    'pretr_frozen': build_swintransformer(pretrained=True, finetune='none', data_augmentation=False),\n","    'pretr_frozen_aug': build_swintransformer(pretrained=True, finetune='none', data_augmentation=True),\n","    'pretr_finetu': build_swintransformer(pretrained=True, finetune='partial', data_augmentation=False),\n","    'pretr_finetu_aug': build_swintransformer(pretrained=True, finetune='partial', data_augmentation=True),\n","}"],"metadata":{"id":"a4x_O1LAuXQi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show the model summaries\n","for model_key, model in try_models.items():\n","  print(f'\\n\\n Summary of {model_key} model \\n\\n')\n","  try_models[model_key].summary()"],"metadata":{"id":"3pvhPeyGJkI6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define ES callback\n","early_stopping = callbacks.EarlyStopping(monitor=\"val_loss\", patience=4)"],"metadata":{"id":"BW9jA2jX8XVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create dataframe for storing test metrics\n","df_test_metrics = pd.DataFrame(columns = ['ModelName','Loss','Accuracy', 'Top3Accuracy'])\n","test_metrics_path = os.path.join(run_dir,'all_models_test_metrics.pkl')"],"metadata":{"id":"9e8OP6jfyatq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Re-make train & val generators that have batch size 1 and aren't shuffled for testing\n","# Note: only test images are used for final test metrics\n","# (but it can also be helpful to see how the model performs on its train & val images)\n","reset_train_generator = datagen.flow_from_directory(train_dir,\n","                                              class_mode = 'sparse', # 'sparse', 'categorical'\n","                                              target_size=(IMG_SIZE, IMG_SIZE),\n","                                              interpolation = 'bicubic',\n","                                              batch_size=1,\n","                                              shuffle=False,\n","                                              seed=123,)\n","\n","reset_val_generator = datagen.flow_from_directory(val_dir,\n","                                            class_mode = 'sparse', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=1,\n","                                            shuffle=False,\n","                                            seed=123,)"],"metadata":{"id":"fno0ueM0J_yX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get filenames and true labels of all images\n","\n","# train \n","reset_train_filenames = reset_train_generator.filenames\n","reset_train_labels = reset_train_generator.labels\n","\n","# val \n","reset_val_filenames = reset_val_generator.filenames\n","reset_val_labels = reset_val_generator.labels\n","\n","# test\n","test_filenames = test_generator.filenames\n","test_labels = test_generator.labels"],"metadata":{"id":"2nvuPWpiKPLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for generating predictions & CMs\n","def plot_CM(generator,best_model,model_key,labels,subset):\n","\n","  generator.reset()\n","  preds = best_model.predict(generator)\n","  binary_preds = preds.argmax(axis=1)\n","\n","  fig, ax = plt.subplots(figsize=(10, 10))\n","  title = f\"Confusion matrix of {model_key} model's\" + os.linesep + f\"predictions on {subset} images\"\n","  cm = confusion_matrix(labels, binary_preds, normalize='true')\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n","  disp.plot(include_values=True, cmap=plt.cm.Blues, ax=ax, xticks_rotation='vertical', values_format=None)\n","  disp.ax_.set_title(title,fontweight='bold')\n","  extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n","\n","  CM_path_eps = CMs_dir + f\"/{model_key}_CM_{subset}.eps\"\n","  fig.savefig(CM_path_eps, format='eps', bbox_inches=extent.expanded(2.0, 2.0))"],"metadata":{"id":"kaz_vZ6yOMzo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 50\n","all_histories = {}\n","\n","model_num = 1\n","\n","for model_key, model in try_models.items():\n","  # finish defining checkpt callback\n","  model_path = os.path.join(saved_models_dir,model_key) # native tf format\n","  save_model = callbacks.ModelCheckpoint(model_path, monitor=\"val_loss\",\n","                                        verbose=1, save_best_only = True,\n","                                        mode='min')\n","  # reset generators\n","  train_generator.reset()\n","  val_generator.reset()\n","  test_generator.reset()\n","  reset_train_generator.reset()\n","  reset_val_generator.reset()\n","\n","  # train & validate\n","  print(f'\\n\\n Training {model_key} \\n\\n')\n","  all_histories[model_key] = model.fit(train_generator,\n","                                       validation_data=val_generator,\n","                                       epochs=EPOCHS,\n","                                       steps_per_epoch=len(train_generator),\n","                                       validation_steps=len(val_generator),\n","                                       class_weight=class_weights,\n","                                       callbacks=[early_stopping, save_model],\n","                                       )\n","  # save model history\n","  model_history = all_histories[model_key].history\n","  history_path = histories_dir  + '/' + model_key + '_history.pckl'\n","  file_pi = open(history_path, 'wb')\n","  pickle.dump(model_history, file_pi)\n","  file_pi.close()\n","\n","  # load in best model\n","  best_model = tf.keras.models.load_model(model_path)\n","\n","  # test on test set\n","  test_results = best_model.evaluate(test_generator) \n","  test_results = dict(zip(best_model.metrics_names,test_results))\n","\n","  # save test metrics\n","  test_loss = test_results['loss']\n","  test_acc = test_results['sparse_categorical_accuracy']\n","  test_top3acc = test_results['sparse_top_3_categorical_accuracy']\n","  df_test_metrics.loc[model_num] = [model_key, test_loss, test_acc, test_top3acc]\n","  df_test_metrics.to_pickle(test_metrics_path)\n","\n","  # predict on train, val, & test\n","  plot_CM(reset_train_generator,best_model,model_key,reset_train_labels,'train')\n","  plot_CM(reset_val_generator,best_model,model_key,reset_val_labels,'val')\n","  plot_CM(test_generator,best_model,model_key,test_labels,'test')\n","\n","  # clear session\n","  tf.keras.backend.clear_session()\n","\n","  model_num += 1\n","\n"],"metadata":{"id":"sekcZtN-wS-f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to retrieve model history, you would do: \n","#file_pi = open(history_path, 'rb')\n","#history = pickle.load(file_pi)\n","#file_pi.close()"],"metadata":{"id":"ixi6x6yV9coi"},"execution_count":null,"outputs":[]}]}