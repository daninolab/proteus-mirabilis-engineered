# -*- coding: utf-8 -*-
"""Copy of 1_Train Models for Proteus Mirabilis Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qrqzH3yqUEWjpSjh4mMCQ6B9nVtqIDAf
"""

# %load_ext autoreload
# %load_ext autotime
# %autoreload 2

#pip install pandas numpy tqdm pillow matplotlib

import os
import time
import math
import random
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm
from pprint import pprint
import pathlib
import PIL
from PIL import Image, ImageOps
import matplotlib.pyplot as plt

import tensorflow as tf

from IPython.display import clear_output

# %config Completer.use_jedi = False
# torch.manual_seed(0)

IMG_SIZE = 512
TRAIN_FRAC = 0.8
BATCH_SIZE=4

def convert_all_to_jpgs(source_folder, target_folder=None, delete_existing_jpg_folder=True, source_ext=".tiff"):

    target_folder = source_folder + "_jpg"
    if delete_existing_jpg_folder and os.path.exists(target_folder):
        shutil.rmtree(target_folder)
    os.mkdir(target_folder)

    for root, dirs, files in os.walk(source_folder, topdown=False):
        for dirname in dirs:
            os.mkdir(f'{target_folder}/{dirname}')
            
    for root, dirs, files in os.walk(source_folder, topdown=False):
        for name in files:
            infile = os.path.join(root, name)
            if '.tiff' in infile:
                outfile = infile.replace(source_folder, target_folder).replace('.tiff', ".jpg")
                with open(outfile, 'w+') as f:
                    im = Image.open(infile)
                    im.thumbnail(im.size)
                    im.save(f, "JPEG", quality=100)

# Mount my google drive
from google.colab import drive # will need to use verification code here
drive.mount('/content/gdrive', force_remount = True)

jpeg_path = 'gdrive/My Drive/images_transformed_512_jpg'
inception_path = 'gdrive/My Drive/saved_inception_pretrained'

# Import all the images into the local environment i guess?
# May need to convert them to grayscale & size 512

def get_available_image_paths(data_root):
  #Get all image paths from my Drive
  all_image_paths = [str(path) for path in data_root.glob('**/*.tiff')]
  print('We have {} images'.format(len(all_image_paths)))
  print(all_image_paths[:2]) #get a sense of where the images are
  return all_image_paths

DEFAULT_IMG_SIZE = 512

def load_and_preprocess_image(path, img_size = DEFAULT_IMG_SIZE):
  #Can't use tensorflow preprocessing because tifs
  img = plt.imread(path)
  img = tf.image.resize(img, [img_size, img_size])
  img /= 255.0  # normalize pixels to 0,1
  return img

root_path = 'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/images_transformed_512'
data_root = pathlib.Path(root_path)
target_folder = 'images_transformed_512'
if not os.path.exists(target_folder):
  os.mkdir(target_folder)

# Get list of folders in the root folder & replicate in the local folder
for root, dirs, files in os.walk(data_root, topdown=False):
        for dirname in dirs:
          if not os.path.exists(f'{target_folder}/{dirname}'):
              os.mkdir(f'{target_folder}/{dirname}')
              print(dirname)

image_paths = get_available_image_paths(data_root)
for i, image_path in enumerate(image_paths):
  try:
    im = Image.open(image_path)
    im.thumbnail((512, 512))
    gray_image = ImageOps.grayscale(im)
    # processed = load_and_preprocess_image(image_path, img_size = 512)
    newpath = image_path.replace('gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/images_transformed_512/', 'images_transformed_512/')
    gray_image.save(newpath)
  except Exception as e:
    print(e)
    print(image_path)
    break

# from image_utils import convert_all_to_jpgs
# import pathlib

# if not os.path.exists('gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/images_transformed_512_jpg'):
#     convert_all_to_jpgs('gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/images_transformed_512')
# data_dir = pathlib.Path('gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/images_transformed_512_jpg')

# try with the local folder
if not os.path.exists('images_transformed_512_jpg'):
    convert_all_to_jpgs('images_transformed_512')
data_dir = pathlib.Path('images_transformed_512_jpg')
PIL.Image.open(str(list(data_dir.glob('*/*.jpg'))[0]))

# from tensorflow import keras
import tensorflow as tf
# from tensorflow.keras.preprocessing.image import image_dataset_from_directory

train_dataset = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.5,
    subset="training",
    label_mode='categorical',
    seed=123,
    color_mode='rgb',
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE)

validation_dataset = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.5,
    subset="validation",
    label_mode='categorical',
    seed=123,
    color_mode='rgb',
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE)

class_names = train_dataset.class_names
print(class_names)

import matplotlib.pyplot as plt
class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
    for i in range(4):
        ax = plt.subplot(2, 2, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i].numpy().argmax()])
        plt.axis("off")
        
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)

print(tf.data.experimental.cardinality(train_dataset))
print(tf.data.experimental.cardinality(validation_dataset))
print(tf.data.experimental.cardinality(test_dataset))


AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
# validation_dataset = validation_dataset.skip(val_batches // 5)

data_augmentations = tf.keras.Sequential([
    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),
    tf.keras.layers.experimental.preprocessing.RandomRotation(0.5, fill_mode='constant'),
    tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1, fill_mode='constant')
])

for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = image[0]

    for i in range(4):
        ax = plt.subplot(2, 2, i + 1)
        augmented_image = data_augmentations(tf.expand_dims(first_image, 0))
        print(augmented_image.numpy().shape)
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')

def create_model(architecture='mobilenetv2', pretrained=False, finetune=True, data_augmentation=True, load_from=None):
    
    base_model = None
    preprocessing = None
    # Download architecture w/ pretrained weights and freeze them
    
#     if load_from is not None and os.path.exists(load_from):
#         loaded_model = tf.keras.models.load_model('load_from')
#         return loaded_model
        
    if architecture.lower() == 'mobilenetv2':
        RESHAPED_SIZE = 224
        base_model = tf.keras.applications.MobileNetV2(
            input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3),
            include_top=False,
            weights=('imagenet' if pretrained else None)
        )
        preprocessing = tf.keras.Sequential([
            tf.keras.layers.Resizing(RESHAPED_SIZE, RESHAPED_SIZE),
            tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)
        ])

    elif architecture.lower() == 'resnet50v2':
        RESHAPED_SIZE = 224
        base_model = tf.keras.applications.ResNet50V2(
            input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3),
            include_top=False,
            weights=('imagenet' if pretrained else None)
        )
        preprocessing = tf.keras.Sequential([
            tf.keras.layers.Resizing(RESHAPED_SIZE, RESHAPED_SIZE),
            tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)
        ])
    
    elif architecture.lower() == 'inceptionv3':
        # RESHAPED_SIZE = 224
        base_model = tf.keras.applications.InceptionV3(
            input_shape=(IMG_SIZE, IMG_SIZE, 3),
            include_top=False,
            weights=('imagenet' if pretrained else None)
        )
        preprocessing = tf.keras.Sequential([
#             tf.keras.layers.Resizing(RESHAPED_SIZE, RESHAPED_SIZE),
            tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)
        ])
    elif architecture.lower() == 'basic':
        base_model = tf.keras.Sequential([
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D((2, 2)),
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu')
        ])
        preprocessing = tf.keras.Sequential([
            tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)
        ])
    else:
        raise ValueError('couldn\'t create model for specified architecture')
    
    if pretrained and finetune: 
        # Let's take a look to see how many layers are in the base model
        print("Number of layers in the base model: ", len(base_model.layers))

        # Fine-tune from this layer onwards
        fine_tune_at = len(base_model.layers) // 3

        # Freeze all the layers before the `fine_tune_at` layer
        for layer in base_model.layers[:fine_tune_at]:
            layer.trainable = False

    elif pretrained:
        base_model.trainable = False

    classification_head = tf.keras.Sequential([
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(len(class_names)),
        tf.keras.layers.Softmax()
    ])

    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    if data_augmentation:
        x = data_augmentations(inputs)
    else:
        x = inputs
        
    x = preprocessing(x)
    x = base_model(x, training=pretrained)
    outputs = classification_head(x)
    model = tf.keras.Model(inputs, outputs)
    
    learning_rate = 0.0001
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss=tf.keras.losses.CategoricalCrossentropy(),
        metrics=[
            'accuracy',
            tf.keras.metrics.CategoricalAccuracy(name="categorical_accuracy"),
            tf.keras.metrics.TopKCategoricalAccuracy(k=3, name="top_k_categorical_accuracy")
        ]
    )
    
    return model

models = {
#     'mobilenet_pretrained': create_model(architecture='mobilenetv2', pretrained=True, finetune=True),
#     'mobilenet_random': create_model(architecture='mobilenetv2', pretrained=False),
    
#     'resnet_pretrained': create_model(architecture='resnet50v2', pretrained=True, finetune=True),
#     'resnet_random': create_model(architecture='resnet50v2', pretrained=False),
    
    'inception_pretrained': create_model(architecture='inceptionv3', pretrained=True, finetune=True),
#     'inception_random': create_model(architecture='inceptionv3', pretrained=False),
    
#     'basic': create_model(architecture='basic', pretrained=False)
}

models['inception_pretrained'].summary()
# models['inception_pretrained'] = tf.keras.models.load_model(inception_path + '/model')

from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

X_train, y_train = zip(*train_dataset.unbatch().as_numpy_iterator())
X_train = np.array(list(X_train)).reshape(len(X_train), -1)
y_train = np.array(list(y_train)).argmax(axis=1)

X_val, y_val = zip(*validation_dataset.unbatch().as_numpy_iterator())
X_val = np.array(list(X_val)).reshape(len(X_val), -1)
y_val = np.array(list(y_val)).argmax(axis=1)

# Train three basic classifiers
linear_svc = SVC(gamma='auto', kernel='linear')
rbf_svc = SVC(gamma='auto', kernel='rbf')
knn = KNeighborsClassifier()


linear_svc.fit(X_train, y_train)
rbf_svc.fit(X_train, y_train)
knn.fit(X_train, y_train)


base_metrics = {}
base_metrics['linear_svc_acc'] = linear_svc.score(X_train, y_train)
base_metrics['linear_svc_val_acc'] = linear_svc.score(X_val, y_val)
base_metrics['rbf_svc_acc'] = rbf_svc.score(X_train, y_train)
base_metrics['rbf_svc_val_acc'] = rbf_svc.score(X_val, y_val)
base_metrics['knn_acc'] = knn.score(X_train, y_train)
base_metrics['knn_val_acc'] = knn.score(X_val, y_val)

from pprint import pprint
pprint(base_metrics)

epochs = 50
histories = {}
test_results = {}
for model_key, model in models.items():
    print(f'\n\n Training {model_key} \n\n')
    histories[model_key] = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)
    test_results[model_key] = model.evaluate(test_dataset)

import os
import json

serialized = {}

for model_key in histories.keys():
    serialized[model_key] = {
        'training_history': histories[model_key].history,
        'test_loss': test_results[model_key][0],
        'test_accuracy': test_results[model_key][1],
        'test_categorical_accuracy': test_results[model_key][2],
        'test_top_3_categorical_accuracy': test_results[model_key][3],
    }

with open('results.json', 'w+') as jsonfile:
    json.dump(serialized, jsonfile)

os.listdir('gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/saved_inception_pretrained/model')

# Save all models
for model_key, model in models.items():
    os.mkdir(f'saved_{model_key}')
    model.save(f'saved_{model_key}/model')



# Save the model in my google drive!
for model_key, model in models.items():
    os.mkdir(f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/saved_{model_key}')
    model.save(f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/saved_{model_key}/model')

results = None
with open('results.json', 'r') as jsonfile:
    results = json.load(jsonfile)

num_train = tf.data.experimental.cardinality(train_dataset).numpy() * BATCH_SIZE
num_val = tf.data.experimental.cardinality(validation_dataset).numpy() * BATCH_SIZE

for model_key, info in results.items():
    print(model_key)
    val_acc = info['training_history']['val_categorical_accuracy'][-1]
    train_acc = info['training_history']['categorical_accuracy'][-1]
    
    overall_acc = ((val_acc * num_val) + (train_acc * num_train)) / (num_train + num_val)
    print(overall_acc)

import tensorflow as tf
best_model = tf.keras.models.load_model('gdrive/My Drive/saved_inception_pretrained/model')
best_model.summary()

X_train, y_train = zip(*train_dataset.unbatch().as_numpy_iterator())
X_train = np.array(list(X_train))
y_train = np.array(list(y_train)).argmax(axis=1)

X_val, y_val = zip(*validation_dataset.unbatch().as_numpy_iterator())
X_val = np.array(list(X_val))
y_val = np.array(list(y_val)).argmax(axis=1)

X = np.concatenate([X_train, X_val])
y = np.concatenate([y_train, y_val])
outputs = best_model(X)

import nvidia_smi

nvidia_smi.nvmlInit()

handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)
# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate

info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)

print("Total memory:", info.total / 1024 / 1024 / 1024)
print("Free memory:", info.free / 1024 / 1024 / 1024)
print("Used memory:", info.used  / 1024 / 1024 / 1024)

val_outputs = best_model(X_val)

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

fig, ax = plt.subplots(figsize=(10, 10))
preds = val_outputs.numpy().argmax(axis=1)

# Plot non-normalized confusion matrix
title = "Confusion matrix for best deep CNN classifier (fine-tuned InceptionV3)"

cm = confusion_matrix(y_val, preds, normalize='true')


disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)


disp.plot(include_values=True, cmap=plt.cm.Blues, ax=ax, xticks_rotation='vertical', values_format=None)


disp.ax_.set_title(title)

plt.show()

extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())

# Pad the saved area by 10% in the x-direction and 20% in the y-direction
# fig.savefig('ax2_figure_expanded.png', bbox_inches=extent.expanded(1.1, 1.2))
fig.savefig('confusion_matrix.eps', format='eps', bbox_inches=extent.expanded(2.0, 2.0))
fig.savefig('confusion_matrix.svg', format='svg', bbox_inches=extent.expanded(2.0, 2.0))

os.listdir('.')

