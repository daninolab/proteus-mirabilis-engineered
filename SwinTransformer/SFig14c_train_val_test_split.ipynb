{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Train-Val-Test split\n","\n","Notebook for randomly splitting datasets into train, valildation, and test subsets (to be used in implementation of SwinTransformer models). Code adapted from Abdul Mukit's post on StackOverflow (2018): https://stackoverflow.com/questions/53074712/how-to-split-folder-of-images-into-test-training-validation-sets-with-stratified"],"metadata":{"id":"N-SeWkVHXgtu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwJPc_Xc-xid"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import numpy as np\n","import shutil\n","import pandas as pd\n","import random"]},{"cell_type":"code","source":["drive.mount('/content/gdrive')"],"metadata":{"id":"f_pY1ewd-1sI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set the path to where i store classifcation stuff \n","drive_classification_dir = '/content/gdrive/MyDrive/Classification_mirabilis/'\n","\n","# and the path to all image dataset \n","img_datasets_dir = drive_classification_dir + 'img_datasets/temperature/'\n","\n","# and the path to the specific dataset to split below \n","this_dataset_name = 'cheW_37' # 'img_dataset_curated' for initial pre-training SwinT; 'cheW_37' for later fine-tuning\n","this_dataset_dir = img_datasets_dir + this_dataset_name + '/'\n","\n","# get a list of the class folders\n","class_folders = os.listdir(this_dataset_dir)\n","print(class_folders)\n","\n","# set path to where I will store train-val-test folders\n","dataset_split_name = this_dataset_name + '_split'\n","dataset_split_dir = img_datasets_dir + dataset_split_name + '/'"],"metadata":{"id":"mtFJKd1n-4gn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# firt determine all class counts\n","for cls in class_folders:\n","  cls_path = this_dataset_dir + cls\n","  cls_imgs = os.listdir(cls_path)\n","  num_imgs = len(cls_imgs)\n","  print(f\"{cls}: {num_imgs} images total\")"],"metadata":{"id":"YOz7wiLhYGyp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform randomized split\n","train_ratio = 0.8\n","val_test_ratio = 0.1\n","\n","for cls in class_folders:\n","\n","  # folder to copy images from \n","  cls_path = this_dataset_dir + cls\n","  allFileNames = os.listdir(cls_path)\n","\n","  # Random shuffle\n","  np.random.shuffle(allFileNames)\n","\n","  train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n","                                                            [int(len(allFileNames) * (1 - (val_test_ratio + val_test_ratio))),\n","                                                             int(len(allFileNames) * (1 - val_test_ratio)),])\n","\n","\n","  train_FileNames = [cls_path + '/' + name for name in train_FileNames.tolist()]\n","  val_FileNames = [cls_path + '/' + name for name in val_FileNames.tolist()]\n","  test_FileNames = [cls_path + '/' + name for name in test_FileNames.tolist()]\n","\n","  print(f\"{cls}\")\n","  print('Total images: '+ str(len(allFileNames)))\n","  print('Training: '+ str(len(train_FileNames)))\n","  print('Validation: '+  str(len(val_FileNames)))\n","  print('Testing: '+ str(len(test_FileNames)))\n","\n","  # Create Train/Val/Test folders \n","  os.makedirs(dataset_split_dir + 'train/' + cls)\n","  os.makedirs(dataset_split_dir + 'val/' + cls)\n","  os.makedirs(dataset_split_dir + 'test/' + cls)\n","\n","  # Copy-paste images\n","  for name in train_FileNames:\n","       shutil.copy(name, dataset_split_dir + 'train/' + cls)\n","\n","  for name in val_FileNames:\n","      shutil.copy(name, dataset_split_dir + 'val/' + cls)\n","\n","  for name in test_FileNames:\n","      shutil.copy(name, dataset_split_dir + 'test/' + cls)\n","\n"],"metadata":{"id":"OIcLeltr-9Kz"},"execution_count":null,"outputs":[]}]}