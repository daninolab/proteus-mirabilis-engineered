{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Fine-tuning of SwinTransformer\n","\n","Subsequent training, validation, and testing of a  Transformer model for the new task of classifying  the relative IPTG concentraion (low vs. high) of *Proteus mirabilis* pLac-*cheW* images. Initiliazing the model with ImageNet weights, as previously done, or our recently acquired all-strain *P. mirabilis* weights, was explored. The model versions were trained on images of pLac-*cheW* grown at 37C and evaluated on unseen test images of the strain grown at 37C, 36C, and 34C. \n","\n","As before, we implement the SwinTransformerTiny224, the shallowest of the SwinTransformer classification models, as originally presented by Liu et al. 2021 and made readily available in Keras (TensorFlow) by Shkarupa<sup>1,2</sup>.\n","\n","[1] Liu, Z., Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo. Swin transformer: Hierarchical vision transformer using shifted windows. in Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n","\n","[2] Shkarupa, A. tfswin. 2022; Available from: https://github.com/shkarupa-alex/tfswin."],"metadata":{"id":"uD-w2YBobsEJ"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"LZoMJ8zyc2zX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cz1M2LAjyg2C"},"outputs":[],"source":["! pip install tfswin"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import numpy as np\n","import shutil\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","import math\n","import inspect\n","from collections import Counter\n","import pickle \n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from tensorflow.keras import preprocessing, layers, models, callbacks\n","from tensorflow.keras.preprocessing import image \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tfswin import SwinTransformerTiny224, preprocess_input  "],"metadata":{"id":"HDmwgQNHTR6Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mount my Google Drive where datasets and models are stored\n","drive.mount('/content/gdrive')"],"metadata":{"id":"rpRdg8k9TYep"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"9P_xd6IogRDG"}},{"cell_type":"code","source":["# Set the path to umbrella directory\n","drive_classification_path = '/content/gdrive/MyDrive/Classification_mirabilis/'\n","\n","# Set the path to all image datasets \n","img_datasets_dir = os.path.join(drive_classification_path,'img_datasets')\n","\n","# Set the path to the specific dataset to use\n","temperature_folder = 'temperature'\n","temperature_path = os.path.join(img_datasets_dir,temperature_folder)\n","\n","# Choose the strain to analyze\n","strain = 'cheW_37' # one of: 'chew' 'lrp' 'flgm' 'flia' 'umod' 'wt' 'gfp'\n","strain_path = os.path.join(temperature_path,strain)\n","strain_split = strain + '_split' # train-val-test split\n","strain_split_path = os.path.join(temperature_path,strain_split)"],"metadata":{"id":"ruBUqaisgXIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get counts (before train-val-test split was done) – for creating visualization plot below\n","class_num = 0\n","cls_img_counts = list()\n","classes = os.listdir(strain_path)\n","for c in classes:\n","  class_num += 1\n","  class_subfolder = os.path.join(strain_path,c)\n","  class_imgs = os.listdir(class_subfolder)\n","  num_imgs = len(class_imgs)\n","  cls_img_counts.append(num_imgs)\n","\n","  print(c)\n","  print(num_imgs)\n","\n","print(cls_img_counts)"],"metadata":{"id":"yVOvKwxijj10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First figure out the img size we should use, \n","# based on the default value used in this specific SwinTransformer\n","size_arg = str(inspect.signature(SwinTransformerTiny224).parameters['pretrain_size'])\n","IMG_SIZE = int(size_arg.split('=')[1])\n","print(IMG_SIZE)"],"metadata":{"id":"Drejhk7vlEbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ImageDataGenerator \n","# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n","\n","TRAIN_BATCH_SIZE = 4\n","VAL_BATCH_SIZE = 4\n","TEST_BATCH_SIZE = 1\n","\n","train_dir = os.path.join(strain_split_path,'train')\n","val_dir = os.path.join(strain_split_path,'val')\n","test_dir_37 = os.path.join(strain_split_path,'test')\n","test_dir_36 = os.path.join(temperature_path,'cheW_36')\n","test_dir_34 = os.path.join(temperature_path,'cheW_34')\n","\n","datagen = ImageDataGenerator()\n","\n","train_generator = datagen.flow_from_directory(train_dir,\n","                                              class_mode = 'categorical', # either 'sparse' or 'categorical' is fine\n","                                              target_size=(IMG_SIZE, IMG_SIZE),\n","                                              interpolation = 'bicubic', # SwinTransformerTiny224 is sensitive to interpolation method\n","                                              batch_size=TRAIN_BATCH_SIZE,\n","                                              shuffle=True,\n","                                              seed=123,)\n","\n","val_generator = datagen.flow_from_directory(val_dir,\n","                                            class_mode = 'categorical', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=VAL_BATCH_SIZE,\n","                                            shuffle=False,\n","                                            seed=123,)\n","\n","test_generator_37 = datagen.flow_from_directory(test_dir_37,\n","                                            class_mode = 'categorical', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=TEST_BATCH_SIZE,\n","                                            shuffle=False,\n","                                            seed=123,)\n","\n","test_generator_36 = datagen.flow_from_directory(test_dir_36,\n","                                            class_mode = 'categorical', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=TEST_BATCH_SIZE,\n","                                            shuffle=False,\n","                                            seed=123,)\n","\n","test_generator_34 = datagen.flow_from_directory(test_dir_34,\n","                                            class_mode = 'categorical', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=TEST_BATCH_SIZE,\n","                                            shuffle=False,\n","                                            seed=123,)"],"metadata":{"id":"960fZXujlWsY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify classes\n","class_names = train_generator.class_indices\n","print(class_names)\n","num_classes = len(class_names)"],"metadata":{"id":"aRvGyV3nlyAn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confirm shapes of batches imgs & labels\n","for image_batch, labels_batch in train_generator:\n","  print(image_batch.shape)\n","  print(labels_batch)\n","  print(labels_batch.shape) # (batch_size, num_classes) if categorical, (batch_size) if sparse\n","  break"],"metadata":{"id":"H0TTIkcCl_-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Determine class counts in each data subset\n","train_counter = Counter(train_generator.classes)    \n","print(train_counter)     \n","val_counter = Counter(val_generator.classes)    \n","print(val_counter)    \n","test_counter_37 = Counter(test_generator_37.classes)    \n","print(test_counter_37)    \n","test_counter_36 = Counter(test_generator_36.classes)    \n","print(test_counter_36) \n","test_counter_34 = Counter(test_generator_34.classes)    \n","print(test_counter_34) "],"metadata":{"id":"HwJQyIwImNXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# B/c the classes are imbalanced, compute class weights for training \n","max_val = float(max(train_counter.values()))    \n","print(max_val)                      \n","class_weights = {class_id : max_val/num_images for class_id, num_images in train_counter.items()}  \n","print(class_weights)"],"metadata":{"id":"YIJsAYoXmPRT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build Model(s) & load in weights"],"metadata":{"id":"d-BpUYZJmdAq"}},{"cell_type":"code","source":["# Set some hyperparamters\n","LR = 1e-5 # initial learning rate\n","EPSILON = 1e-8\n","\n","# Number of steps after which to reduce learning rate\n","# (one step refers to the execution of one batch of data)\n","DECAY_STEPS = 13\n","ALPHA = 0.0 # Minimum learning rate value as a fraction of initial_learning_rate\n","DECAY_RATE = 0.96\n","LR_schedule = tf.keras.optimizers.schedules.ExponentialDecay(LR,\n","                                                             decay_steps=DECAY_STEPS,\n","                                                             decay_rate=DECAY_RATE)"],"metadata":{"id":"UTcRn4zCmeM7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Potential additional on-the-fly augmentations\n","augs_on_the_fly = tf.keras.Sequential([\n","    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',input_shape=(IMG_SIZE,IMG_SIZE,3)),\n","    tf.keras.layers.experimental.preprocessing.RandomZoom((-0.1, -0.02)), # neg for zoom in by random amnt in range [+2%, +10%]\n","    tf.keras.layers.experimental.preprocessing.RandomContrast(0.4),\n","    tf.keras.layers.experimental.preprocessing.RandomRotation((-0.01, 0.01),fill_mode='reflect'),\n","    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=(-0, 0),width_factor=(-0.1, 0.1),fill_mode='reflect')],\n","    name='on_fly_augs')"],"metadata":{"id":"CG-EAYkdmkIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for building model\n","# finetune='partial','full','none' \n","\n","def build_swintransformer(num_classes, pretrained=False, finetune='full', data_augmentation=False):\n","  \n","  # first reset all layers\n","  inputs = None\n","  preproces = None\n","  swin_model = None\n","  classification_head = None\n","\n","  # define input shape\n","  inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3),name='input_new')\n","  \n","  # optional on-the-fly training augs\n","  if data_augmentation:\n","    x = augs_on_the_fly(inputs)\n","  else:\n","    x = inputs\n","\n","  # preprocess layer\n","  preproces = tf.keras.Sequential([tf.keras.layers.Lambda(preprocess_input)],\n","                                  name='preprocess_new')\n","\n","  # swin\n","  swin_model = SwinTransformerTiny224(weights=('imagenet' if pretrained else None),\n","                                      include_top=False)\n","  if finetune == 'full':\n","    swin_model.trainable = True\n","  elif finetune == 'none': \n","    swin_model.trainable = False\n","  elif finetune == 'partial':     \n","    # Let's take a look to see how many layers are in the base model\n","    print(\"Number of layers in the base swin model: \", len(swin_model.layers))\n","    # Fine-tune from this layer onwards\n","    fine_tune_at = len(swin_model.layers) // 3\n","    # Freeze all the layers before the `fine_tune_at` layer\n","    for layer in swin_model.layers[:fine_tune_at]:\n","      layer.trainable = False\n","\n","  # classification head\n","  classification_head = tf.keras.Sequential([\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(num_classes, activation='softmax'),\n","        ],name='class_head_new')\n","  \n","  # put it all together\n","  x = preproces(x)\n","  x = swin_model(x, training=pretrained)\n","  outputs = classification_head(x)\n","  model = tf.keras.Model(inputs, outputs)\n","\n","  # compile model\n","  model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LR_schedule, epsilon=EPSILON),\n","                loss=tf.keras.losses.CategoricalCrossentropy(),\n","                metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\"),\n","                         tf.keras.metrics.AUC(name='AUC',multi_label=False)\n","                         ],\n","               )\n","\n","  return model "],"metadata":{"id":"nHaBFBpymnPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First instantiate the same model that we found to be best on the all-strain dataset\n","# (it had 6 classes for 6 strains).\n","# We need to do this to grab its weights to load into a new model.\n","former_model = build_swintransformer(num_classes=6, pretrained=True, finetune='full', data_augmentation=True)"],"metadata":{"id":"kW6gd6w8k_e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Weights from the last model\n","former_run_name = 'SwinTransformerTiny224_curateddataset_pretr_finetu_aug'\n","former_run_dir = os.path.join(drive_classification_path,former_run_name)\n","former_best_model_name = 'pretr_aug'\n","former_best_model_path = os.path.join(former_run_dir,'saved_models',former_best_model_name)\n","former_model.load_weights(former_best_model_path)"],"metadata":{"id":"6DiJTbS7leQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["former_model.summary()"],"metadata":{"id":"p0brDV_pm_qd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["former_swin_weights = former_model.layers[3].get_weights()\n","print(f\"Shape of SwinTransformer's weights: {former_swin_weights[0].shape}\") \n","print(f\"Shape of SwinTransformer's biases: {former_swin_weights[1].shape}\") "],"metadata":{"id":"NQtRI_p9nCgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create folder for this new run\n","run_name = 'SwinT_adaptLR_chew_TempRobust_ExpDecay_13DC_0pt96DR_pat10'\n","run_dir = os.path.join(drive_classification_path,run_name)\n","\n","saved_models_dir = os.path.join(run_dir,'saved_models')\n","histories_dir = os.path.join(run_dir,'histories')\n","CMs_dir = os.path.join(run_dir,'confusion_matrices')\n","\n","all_run_dirs = [run_dir, saved_models_dir, histories_dir, CMs_dir]\n","\n","for run_sub_dir in all_run_dirs:\n","  if not(os.path.isdir(run_sub_dir)):\n","    os.mkdir(run_sub_dir)"],"metadata":{"id":"8A7DWoNSy7b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now instantiate new models to train on single strain, binned by iptg\n","# (the only difference from above is # classes)\n","# for some of the models, we'll then load in the P. mirabilis (PM) weights of the above swin layer,\n","# rather than ImageNet (IN) weights\n","\n","try_models = {\n","    'PM FFT': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='full', data_augmentation=False), \n","    'PM FFT Aug': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='full', data_augmentation=True),\n","    'PM PFT': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='partial', data_augmentation=False),\n","    'PM PFT Aug': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='partial', data_augmentation=True),\n","    'IN FFT': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='full', data_augmentation=False),\n","    'IN FFT Aug': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='full', data_augmentation=True),\n","    'IN PFT': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='partial', data_augmentation=False),\n","    'IN PFT Aug': build_swintransformer(num_classes=num_classes,pretrained=True, finetune='partial', data_augmentation=True),\n","}"],"metadata":{"id":"c3dm818fyd5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show the model summaries\n","for model_key, model in try_models.items():\n","  print(f'\\n\\n Summary of {model_key} model \\n\\n')\n","  try_models[model_key].summary()"],"metadata":{"id":"ovVA2ezb0IRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load in P. mirabilis weights for specified models\n","for model_key, model in list(try_models.items()):\n","  if 'PM' in model_key:\n","    print(model_key)\n","    try_models[model_key].layers[-2].set_weights(former_swin_weights)"],"metadata":{"id":"azYd8zsdLREh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training & validation"],"metadata":{"id":"XyuubC9v65s1"}},{"cell_type":"code","source":["# define ES callback\n","early_stopping = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)"],"metadata":{"id":"Mgmn9u2U6wFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# re-make train & val generators that have batch size 1 and aren't shuffled for testing\n","# Note: only test images are used for final test metrics\n","# (but it can also be helpful to see how the model performs on its train & val images)\n","reset_train_generator = datagen.flow_from_directory(train_dir,\n","                                              class_mode = 'categorical', # 'sparse', 'categorical'\n","                                              target_size=(IMG_SIZE, IMG_SIZE),\n","                                              interpolation = 'bicubic',\n","                                              batch_size=1,\n","                                              shuffle=False,\n","                                              seed=123,)\n","\n","reset_val_generator = datagen.flow_from_directory(val_dir,\n","                                            class_mode = 'categorical', # 'sparse', 'categorical'\n","                                            target_size=(IMG_SIZE, IMG_SIZE),\n","                                            interpolation = 'bicubic',\n","                                            batch_size=1,\n","                                            shuffle=False,\n","                                            seed=123,)"],"metadata":{"id":"WY0K18gn7Hm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get filenames and true labels of all images\n","\n","# train \n","reset_train_filenames = reset_train_generator.filenames\n","reset_train_labels = reset_train_generator.labels\n","\n","# val \n","reset_val_filenames = reset_val_generator.filenames\n","reset_val_labels = reset_val_generator.labels\n","\n","# test\n","test_filenames_37 = test_generator_37.filenames\n","test_labels_37 = test_generator_37.labels\n","test_filenames_36 = test_generator_36.filenames\n","test_labels_36 = test_generator_36.labels\n","test_filenames_34 = test_generator_34.filenames\n","test_labels_34 = test_generator_34.labels"],"metadata":{"id":"Qwk5p1Sg7LJg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for generating predictions & CMs\n","def plot_CM(generator,best_model,model_key,labels,subset):\n","\n","  generator.reset()\n","  preds = best_model.predict(generator)\n","  binary_preds = preds.argmax(axis=1)\n","\n","  fig, ax = plt.subplots(figsize=(10, 10))\n","  title = f\"Confusion matrix of {model_key} model's\" + os.linesep + f\"predictions on cheW {subset} images\"\n","  cm = confusion_matrix(labels, binary_preds, normalize=None)\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n","  disp.plot(include_values=True, cmap=plt.cm.Blues, ax=ax, xticks_rotation='vertical', values_format=None)\n","  disp.ax_.set_title(title,fontweight='bold')\n","  extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n","  plt.rcParams['svg.fonttype'] = 'none' \n","\n","  CM_path = CMs_dir + f\"/{model_key}_CM_{subset}.svg\"\n","  fig.savefig(CM_path, format='svg', bbox_inches=extent.expanded(2.0, 2.0))"],"metadata":{"id":"0O3T-Az07Nu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 50\n","all_histories = {}\n","\n","\n","for model_key, model in try_models.items():\n","  # finish defining checkpt callback\n","  model_path = os.path.join(saved_models_dir,model_key) # native tf format\n","  save_model = callbacks.ModelCheckpoint(model_path, monitor=\"val_loss\",\n","                                        verbose=1, save_best_only = True,\n","                                        mode='min')\n","  # reset generators\n","  train_generator.reset()\n","  val_generator.reset()\n","  test_generator_37.reset()\n","  test_generator_36.reset()\n","  test_generator_34.reset()\n","  reset_train_generator.reset()\n","  reset_val_generator.reset()\n","\n","  # train & validate\n","  print(f'\\n\\n Training {model_key} \\n\\n')\n","  all_histories[model_key] = model.fit(train_generator,\n","                                       validation_data=val_generator,\n","                                       epochs=EPOCHS,\n","                                       steps_per_epoch=len(train_generator),\n","                                       validation_steps=len(val_generator),\n","                                       class_weight=class_weights,\n","                                       callbacks=[early_stopping, save_model],\n","                                       )\n","  # save model history\n","  model_history = all_histories[model_key].history\n","  history_path = histories_dir  + '/' + model_key + '_history.pckl'\n","  file_pi = open(history_path, 'wb')\n","  pickle.dump(model_history, file_pi)\n","  file_pi.close()\n","\n","  # load in best model\n","  best_model = tf.keras.models.load_model(model_path)\n","\n","  # create dataframe for storing test metrics\n","  df_test_metrics = pd.DataFrame(index = ['37C','36C','34C'],\n","                               columns = ['Loss','Accuracy','AUC'])\n","  test_metrics_path = os.path.join(run_dir,f\"{model_key}_test_metrics.pkl\")\n","\n","  # test on test sets\n","  test_results_37 = best_model.evaluate(test_generator_37) \n","  test_results_37 = dict(zip(best_model.metrics_names,test_results_37))\n","  test_results_36 = best_model.evaluate(test_generator_36) \n","  test_results_36 = dict(zip(best_model.metrics_names,test_results_36))\n","  test_results_34 = best_model.evaluate(test_generator_34) \n","  test_results_34 = dict(zip(best_model.metrics_names,test_results_34))\n","  \n","  # save test metrics\n","  test_loss_37 = test_results_37['loss']\n","  test_acc_37 = test_results_37['categorical_accuracy']\n","  test_AUC_37 = test_results_37['AUC']\n","  test_loss_36 = test_results_36['loss']\n","  test_acc_36 = test_results_36['categorical_accuracy']\n","  test_AUC_36 = test_results_36['AUC']\n","  test_loss_34 = test_results_34['loss']\n","  test_acc_34 = test_results_34['categorical_accuracy']\n","  test_AUC_34 = test_results_34['AUC']\n","  df_test_metrics.loc['37C'] = [test_loss_37, test_acc_37, test_AUC_37]\n","  df_test_metrics.loc['36C'] = [test_loss_36, test_acc_36, test_AUC_36]\n","  df_test_metrics.loc['34C'] = [test_loss_34, test_acc_34, test_AUC_34]\n","  df_test_metrics.to_pickle(test_metrics_path)\n","\n","  # predict on train, val, & test\n","  plot_CM(reset_train_generator,best_model,model_key,reset_train_labels,'37C train')\n","  plot_CM(reset_val_generator,best_model,model_key,reset_val_labels,'37C val')\n","  plot_CM(test_generator_37,best_model,model_key,test_labels_37,'37C test')\n","  plot_CM(test_generator_36,best_model,model_key,test_labels_36,'36C test')\n","  plot_CM(test_generator_34,best_model,model_key,test_labels_34,'34C test')\n","\n","  # clear session\n","  tf.keras.backend.clear_session()"],"metadata":{"id":"PeBh5wTH7a0T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"bz9EsZ2bm84O"}}]}