# -*- coding: utf-8 -*-
"""Upload Version 110122_Evaluate_Trained_Efficientnet_Learningcurves_Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10_OhRLlxFTaVHDeHMyjhzwxrDN7W4p8I

# Overview

In this notebook we will load the saved Efficientnet models and their training history, plot the histories and save nicely, evaluate the models on the intermediate images dataset, plot the results and save that too.

## Imports
"""

import os
import shutil
import time
import math
import random
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm
from pprint import pprint
import pathlib
import PIL
from PIL import Image, ImageOps
import matplotlib.pyplot as plt
plt.rcParams['svg.fonttype'] = 'none'
import pickle

import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator

from IPython.display import clear_output
import cv2 as cv
from sklearn import model_selection
from sklearn.metrics import mean_squared_error

# %config Completer.use_jedi = False
# torch.manual_seed(0)
!pip  install tensorflow-gpu
!pip install tensorflow==2.8
!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2
from tensorflow.keras.applications import *
from tensorflow.keras import models, layers, callbacks

plt.rcParams['svg.fonttype'] = 'none'
date_string = '013023'
# date_string = '111022'

#Use this to check if the GPU is configured correctly
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

IMG_SIZE = 512

# Mount my google drive
from google.colab import drive # will need to use verification code here
drive.mount('/content/gdrive', force_remount = True)

import matplotlib.image as mpimg
import seaborn as sns
sns.set_style('white')

from matplotlib import colors as mcolors
colors = dict(**mcolors.CSS4_COLORS)
print(colors)
print(list(colors)[3])

sns.set_theme()

"""# Importing the data"""

# Import all the images into the local environment i guess?
# May need to convert them to grayscale & size 512

def get_available_image_paths(data_root):
  #Get all image paths from my Drive
  all_image_paths = [str(path) for path in data_root.glob('**/*.jpg')]
  print('We have {} images'.format(len(all_image_paths)))
  print(all_image_paths[:2]) #get a sense of where the images are
  return all_image_paths



def load_and_preprocess_image(path, img_size = IMG_SIZE):
  #Can't use tensorflow preprocessing because tifs
  img = plt.imread(path)
  
  img = tf.image.resize(img, [img_size, img_size])
  
  # img /= 255.0  # normalize pixels to 0,1
  return img

root_path = 'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/Updated_ML_Dataset_103022/All_Ims_For_Upload'
data_root = pathlib.Path(root_path)
target_folder = 'images_transformed_512'
if not os.path.exists(target_folder):
  os.mkdir(target_folder)

# Get list of folders in the root folder & replicate in the local folder
for root, dirs, files in os.walk(data_root, topdown=False):
        for dirname in dirs:
          if not os.path.exists(f'{target_folder}/{dirname}'):
              os.mkdir(f'{target_folder}/{dirname}')
              print(dirname)

image_paths = get_available_image_paths(data_root)
for i, image_path in enumerate(image_paths):
  try:
    im = Image.open(image_path)
    im.thumbnail((512, 512))
    # gray_image = ImageOps.grayscale(im)
    # processed = load_and_preprocess_image(image_path, img_size = 512)
    newpath = image_path.replace('gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/Updated_ML_Dataset_103022/All_Ims_For_Upload', 'images_transformed_512/')
    # gray_image.save(newpath)
    im.save(newpath)
  except Exception as e:
    print(e)
    print(image_path)
    break

# now let's get the labels
new_image_paths = get_available_image_paths(pathlib.Path('images_transformed_512'))
print(new_image_paths[0:3])

# Let's set from the get go whether we want to normalize the labels or not
normalize_conc_labels = True

# # let's make a dict for the labels


if normalize_conc_labels:
  class_dict = {"0_iptg_0.1_ara": [0, 0.5],
              "0_iptg_0.2_ara": [0, 1],
              "0_iptg_0_ara": [0, 0],
              "2.5_iptg_0.1_ara": [0.5, 0.5],
              "2.5_iptg_0.2_ara": [0.5, 1],
              "2.5_iptg_0_ara": [0.5, 0],
              "5_iptg_0.1_ara": [1.0, 0.5],
              "5_iptg_0.2_ara": [1.0, 1],
              "5_iptg_0_ara": [1.0, 0]}

else:
  class_dict = {"0_iptg_0.1_ara": [0, 0.1],
                "0_iptg_0.2_ara": [0, 0.2],
                "0_iptg_0_ara": [0, 0],
                "2.5_iptg_0.1_ara": [2.5, 0.1],
                "2.5_iptg_0.2_ara": [2.5, 0.2],
                "2.5_iptg_0_ara": [2.5, 0],
                "5_iptg_0.1_ara": [5.0, 0.1],
                "5_iptg_0.2_ara": [5.0, 0.2],
                "5_iptg_0_ara": [5.0, 0]}

for key in class_dict:
  print(key)
  print(class_dict[key])

print(os.listdir('images_transformed_512'))
total = 0
for root, dirs, main_files in os.walk('images_transformed_512'):
    for dir in dirs:
      print(dir)
      if not  "Intermediate" in dir:
        print(class_dict[dir])
        for img_root, img_dirs, img_files in os.walk(os.path.join('images_transformed_512', dir)):
          for img_file in img_files:
            total += 1

print("Num ims for training")
print(total)

# Get number of images per class
total = 0
for root, dirs, main_files in os.walk('images_transformed_512'):
    for dir in dirs:
      print(dir)
      if not  "Intermediate" in dir:
        # print(class_dict[dir])
        for img_root, img_dirs, img_files in os.walk(os.path.join('images_transformed_512', dir)):
          for img_file in img_files:
            total += 1
      print(total)
      total = 0

# get the new image paths
# THIS DOESN'T WORK
data_dir = pathlib.Path('/content/images_transformed_512')
new_image_paths = [str(path) for path in data_dir.glob('*/*.jpg')]
print(new_image_paths[0:3])


# PIL.Image.open(str(list(data_dir.glob('*/*.jpg'))[0]))

"""# Build the datasets"""

# Make the main training set & intermediate evaluation set at same time

X_full = []
y_full = []
img_paths_full = []

X_full_int = []
y_full_int = []
img_paths_full_int = []

for img_path in new_image_paths:
  if not  "Intermediate" in img_path:
    img_dir = img_path.split('/')[3]
    img_number = class_dict[img_dir]
    # preprocess image for inceptionv3
    im = cv.imread(img_path)
    im = cv.resize(im, (IMG_SIZE, IMG_SIZE))
    # img_processed = tf.keras.applications.inception_v3.preprocess_input(im, data_format=None)
    # img_processed = load_and_preprocess_image(image_path, img_size = 512)
    
    # make dataset in full
    X_full.append(im)

    # for regression
    y_full.append(img_number)

    # in case we need it later, save the image path
    img_paths_full.append(img_path)

  else:
    # This is a diff concentration image
    # Get the IPTG, ara
    img_name = img_path.split('/')[4]
    img_name_split = img_name.split('_')
    img_number = [float(img_name_split[0]), float(img_name_split[2])]
    # decide whether we need to normalize or not:
    if normalize_conc_labels:
      img_number[0] = img_number[0]/5.0
      img_number[1] = img_number[1]/0.2

    # resize image and add to matrix
    im = cv.imread(img_path)
    im = cv.resize(im, (IMG_SIZE, IMG_SIZE))
    X_full.append(im)
    y_full.append(img_number)
    img_paths_full.append(img_path)

# Review the datasets 

print(len(X_full))
print(X_full[0].shape)

print(len(y_full))
print(y_full[0])


# Double check the images
plt.figure()
plt.imshow(X_full[0])
plt.title(y_full[0])
plt.figure()
plt.imshow(X_full[1])
plt.title(y_full[1])

"""Convert the datasets to tensors"""

# conver to tensors
X_full = tf.convert_to_tensor(X_full)
y_full = tf.convert_to_tensor(y_full)

assert len(X_full) == len(y_full)
print('{} length data'.format(len(X_full)))

# build the train/test/val from the desired date

with open(f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/{date_string}_trainims.txt', 'r') as writefile:
    paths_train = writefile.readlines()
    for idx,temppath in enumerate(paths_train):
      paths_train[idx]=temppath.strip()
with open(f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/{date_string}_valims.txt', 'r') as writefile:
    paths_val = writefile.readlines()
    for idx,temppath in enumerate(paths_val):
      paths_val[idx]=temppath.strip()
with open(f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/{date_string}_testims.txt', 'r') as writefile:
    paths_test = writefile.readlines()
    for idx,temppath in enumerate(paths_test):
      paths_test[idx]=temppath.strip()

train_idxs = []
val_idxs = []
test_idxs = []
for idx, img_path in enumerate(img_paths_full):
  if img_path in paths_train:
    train_idxs.append(idx)
  elif img_path in paths_val:
    val_idxs.append(idx)
  elif img_path in paths_test:
    test_idxs.append(idx)
print(len(train_idxs))
print(len(val_idxs))
print(len(test_idxs))


train_idxs = tf.convert_to_tensor(train_idxs)
val_idxs = tf.convert_to_tensor(val_idxs)
test_idxs = tf.convert_to_tensor(test_idxs)

print('starting X train')
X_train = tf.gather(X_full, train_idxs)
print('starting X val')
X_val = tf.gather(X_full, val_idxs)
print('starting X test')
X_test = tf.gather(X_full, test_idxs)
print('starting y train')
y_train = tf.gather(y_full, train_idxs)
print('starting y val')
y_val = tf.gather(y_full, val_idxs)
print('starting y test')
y_test = tf.gather(y_full, test_idxs)

# See which classes are present in val & test

from collections import Counter

print("val")
y_val_array = np.asarray(y_val)
unique_rows, counts = (np.unique(y_val_array, axis=0, return_counts=True))
print(unique_rows)
print(counts)
print("test")
y_test_array = np.asarray(y_test)
unique_rows, counts = (np.unique(y_test_array, axis=0, return_counts=True))
print(unique_rows)
print(counts)

"""# Build the models & load saved weights"""

def build_efficientnet(architecture='EfficientNetB0', pretrained=False, finetune=True, data_augmentation=True, load_from=None):
    
    base_model = None
    preprocessing = None
    RESHAPED_SIZE = 224
    # Note that all the efficientnets do the rescaling from 0-255 to 0-1 internally
    # Download architecture w/ pretrained weights and freeze them
    if architecture.lower() == 'EfficientNetB0'.lower():
      base_model = EfficientNetB0(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB1'.lower():
      base_model = EfficientNetB1(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB2'.lower():
      base_model = EfficientNetB2(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB3'.lower():
      base_model = EfficientNetB3(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB4'.lower():
      base_model = EfficientNetB4(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB5'.lower():
      base_model = EfficientNetB5(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB6'.lower():
      base_model = EfficientNetB6(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))
    elif architecture.lower() == 'EfficientNetB7'.lower():
      base_model = EfficientNetB7(weights="imagenet" if pretrained else None, include_top=False, input_shape=(RESHAPED_SIZE, RESHAPED_SIZE, 3))

    # Let's build the rest of the model
    preprocessing = tf.keras.Sequential([tf.keras.layers.Resizing(RESHAPED_SIZE, RESHAPED_SIZE)])

    # Specify how much we want to fine-tune
    if pretrained and finetune: 
      # Let's take a look to see how many layers are in the base model
      print("Number of layers in the base model: ", len(base_model.layers))
      # Fine-tune from this layer onwards
      fine_tune_at = len(base_model.layers) // 3
      # Freeze all the layers before the `fine_tune_at` layer
      for layer in base_model.layers[:fine_tune_at]:
          layer.trainable = False
    elif pretrained:
      base_model.trainable = False

    # Build the classification head for regression--2 outputs, linear activation only
    classification_head = tf.keras.Sequential([
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(2)
        # No activation specified should give us a linear activation output
    ])

    # Start to put together the full model, specifying augmentations if desired
    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    if data_augmentation:
        x = data_augmentations(inputs)
    else:
        x = inputs

    x = preprocessing(x)
    x = base_model(x, training=True)
    outputs = classification_head(x)
    model = tf.keras.Model(inputs, outputs)

    # compile the model
    learning_rate = 0.0001
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        learning_rate,
        decay_steps=100000,
        decay_rate=0.96)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
        # THIS IS THE OTHER CHANGE--going to use MSE for regression output
        loss = tf.keras.losses.MeanSquaredError(),
        metrics = ['MeanAbsoluteError'],
        steps_per_execution = 1
    )

    return model

#Since our data generator has augmentation, we won't add it into the models here

try_models = {
    # 'b0': build_efficientnet(architecture = 'EfficientNetB0', pretrained=True, finetune=True, data_augmentation=False),
    # 'b1': build_efficientnet(architecture = 'EfficientNetB1', pretrained=True, finetune=True, data_augmentation=False),
    'b2': build_efficientnet(architecture = 'EfficientNetB2', pretrained=True, finetune=True, data_augmentation=False)
    # 'b3': build_efficientnet(architecture = 'EfficientNetB3', pretrained=True, finetune=True, data_augmentation=False)
    # 'b4': build_efficientnet(architecture = 'EfficientNetB4', pretrained=True, finetune=True, data_augmentation=False)
    # 'b5': build_efficientnet(architecture = 'EfficientNetB5', pretrained=True, finetune=True, data_augmentation=False),
    # 'b6': build_efficientnet(architecture = 'EfficientNetB6', pretrained=True, finetune=True, data_augmentation=False),
    # 'b7': build_efficientnet(architecture = 'EfficientNetB7', pretrained=True, finetune=True, data_augmentation=False),
}

for model_key, model in try_models.items():
  # get the location it is saved
  
  model_weights_file = f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/{date_string}_{model_key}_alldata/ckpt'
  model.load_weights(model_weights_file)
  # now we have updated the weights, hopefully

"""# Evaluate the models on the datasets and plot results"""

# EVALUATE AND VISUALIZE RESULTS
from sklearn.metrics import mean_squared_error

# y_pred = model.predict(X_test)
# print("MSE: %.4f" % mean_squared_error(y_test, y_pred))

y_pred_val = model.predict(X_val)
print("MSE: %.4f" % mean_squared_error(y_val, y_pred_val))
y_pred_test = model.predict(X_test)
print("MSE: %.4f" % mean_squared_error(y_test, y_pred_test))

y_preds = [y_pred_val, y_pred_test]
y_val_and_test_labels = [y_val, y_test]
titles = ['Predictions on Val', 'Predictions on Test']

# Now let's evaluate on the intermediate dataset!
palette = sns.color_palette("viridis", 25).as_hex()
#palette_2 = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000']
palette_2 = ['#e6194b', '#3cb44b', '#911eb4', '#46f0f0', '#e6194b', '#3cb44b', '#911eb4', '#46f0f0']

# Now instead of these lines, let's make individual IPTG, ara error bar versions

fig, ax = plt.subplots(2, 2, figsize = [20, 10])

titles = ['IPTG preds on val', 'ara preds on val', 'IPTG preds on test', 'ara preds on test']

for idx, y_pred in enumerate(y_preds): 
  print(idx)
  print('Val, then test')
  # the first one is val, second is test
  y_labels_temp = y_val_and_test_labels[idx]
  y_labels_temp = np.array(y_labels_temp)
  # Let's do IPTGs, then aras
  for molecule_idx in range(2):
    unique_vals = np.unique(y_labels_temp[:, molecule_idx])
    for true_val in unique_vals:
      curr_preds = []
      true_vals = []
      for lbl_idx, lbl in enumerate(y_labels_temp):
        if lbl[molecule_idx] == true_val:
          curr_preds.append(y_pred[lbl_idx, molecule_idx])
          true_vals.append(true_val)
      # Now that we have gotten all the preds that go with that val, let's multiply them
      curr_preds = np.array(curr_preds)
      true_vals = np.array(true_vals)
      if molecule_idx == 0:
        curr_preds = curr_preds*5.0
        true_vals = true_vals*5.0
      else:
        curr_preds = curr_preds*0.2
        true_vals = true_vals*0.2

      # now calculate the error
      err_val = np.sqrt(mean_squared_error(true_vals, curr_preds))
      mean_pred = np.mean(curr_preds)

      # For figure caption, let's print the n here
      print(molecule_idx)
      print(true_val)
      print(len(true_vals))

      # now plot
      if molecule_idx ==0:
        multiply_val = 5.0
      else:
        multiply_val = 0.2
      # i don't think this plot is actually valid?
      ax[idx, molecule_idx].errorbar(true_val*multiply_val, mean_pred,
                     yerr= err_val, 
                     fmt='o', color = palette_2[1], ecolor = '#2596be',
                     capsize = 7) 

    ax[idx, molecule_idx].plot(unique_vals*multiply_val, unique_vals*multiply_val,
                  color = '#2596be', linestyle ='--')
   
  # Format the recent two plots before moving on
  ax[idx, 0].set_title(titles[idx*2])
  ax[idx, 0].set_xlabel('True IPTG')
  ax[idx, 0].set_ylabel('Pred IPTG')
  ax[idx, 1].set_title(titles[idx*2+1])
  ax[idx, 1].set_xlabel('True ara')
  ax[idx, 1].set_ylabel('Pred ara')



    



extent = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
save_dir = f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/plots'
curves_path = save_dir + f'/{date_string}_val_and_test_errplots.svg'
fig.savefig(curves_path, format='svg', bbox_inches="tight")

# Display predictions on test images
mult_vals = np.array([5, 0.2])
fig = plt.figure(figsize = [15, 15])
for i, val in enumerate(range(25)):
  im = X_test[i, :, :, :]
  im = im[...,::-1]
  plt.subplot(5, 5, i+1)
  plt.imshow(im, cmap='gray')
  true_val = np.array(y_test[i, :])
  pred_val = np.array(y_pred_test[i, :])
  true_val = true_val*mult_vals
  pred_val = pred_val*mult_vals
  plt.title('True {:1.2}i {:1.2}a \n Pred {:1.2}i {:1.2}a'.format(true_val[0], true_val[1], pred_val[0], pred_val[1]))
  plt.axis('off')


# Get the date for later saving
from datetime import date
today = date.today()
curr_date = today.strftime("%m%d%y")

extent = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
save_dir = f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/plots'
curves_path = save_dir + f'/{date_string}_test_impreds_vis_{curr_date}.svg'
fig.savefig(curves_path, format='svg', bbox_inches="tight")

"""# Load the saved histories & plot"""

# histories_dir = 'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/histories/'
# histories_list = os.listdir(histories_dir)
# print(histories_list)

history_file = 'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/111022_b2_all_data_history_file'

def plot_multiple(history, model_name, linecolor, ALPHA, MARKER):
  
  # The history object contains results on the training and test
  # sets for each epoch
  acc = history['mean_absolute_error']
  val_acc = history['val_mean_absolute_error']
  loss = history['loss']
  val_loss = history['val_loss']

  min_val_loss = min(val_loss)
  best_epoch = val_loss.index(min_val_loss) + 1

  max_loss = max(loss)

  # Get the number of epochs
  epochs_completed = len(loss)
  epochs_range = range(1,epochs_completed+1)
  
  # loss
  plt.subplot(1, 2, 1)
  plt.plot(epochs_range, loss, color=linecolor, linestyle='dashed', alpha = ALPHA, label=f'Train {model_name}')
  plt.plot(epochs_range, val_loss, color=linecolor, alpha = ALPHA, label=f'Val {model_name}')
  plt.scatter(x=best_epoch,y=min_val_loss,marker=MARKER,alpha = ALPHA,c=linecolor)
  plt.ylim([0, max_loss+0.05])

  # acc
  plt.subplot(1, 2, 2)
  plt.plot(epochs_range, acc, color=linecolor, linestyle='dashed', alpha = ALPHA, label=f'Train {model_name}')
  plt.plot(epochs_range, val_acc, color=linecolor, alpha = ALPHA, label=f'Val {model_name}')

def format_histories_plot(max_epochs):
  plt.subplot(1, 2, 1)
  plt.title('Mean Squared Error')
  plt.xlabel('Epoch',fontsize=10)
  plt.ylabel('MSQ',fontsize=10)
  plt.xticks(ticks=np.arange(1,max_epochs+1,4))
  plt.yticks(ticks=np.arange(0,0.45,0.1))
  #plt.legend(bbox_to_anchor=(1.33, 1))
  plt.legend(facecolor='white',edgecolor='gray')

  plt.subplot(1, 2, 2)
  plt.title('Mean Absolute Error')
  plt.xlabel('Epoch',fontsize=10)
  plt.ylabel('MAE',fontsize=10)
  plt.xticks(ticks=np.arange(1,max_epochs+1,4))
  plt.yticks(ticks=np.arange(0,0.6,0.2))
  #plt.legend(bbox_to_anchor=(1.33, 1))



  fig.suptitle('Regression on cheWumoD Images with Efficientnets',y=0.91,fontweight='bold')

fig, ax = plt.subplots(figsize = [30, 20])
idx = 0
palette = sns.color_palette("viridis", 25).as_hex()
#palette_2 = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000']
palette_2 = ['#e6194b', '#3cb44b', '#911eb4', '#46f0f0', '#e6194b', '#3cb44b', '#911eb4', '#46f0f0']
all_epochs_completed = list()

# for history_file in histories_list:

  # model_name = history_file.replace('_history_file','')
  # history_path = os.path.join(histories_dir,history_file)

model_name = 'EfficientNetb2'
history_path = history_file
file_pi = open(history_path, 'rb')
history = pickle.load(file_pi)
file_pi.close()

eps = len(history['loss'])
all_epochs_completed.append(eps)
ALPHA = 1
MARKER = 'o'
LINESTYLE = 'solid'
linecolor = palette_2[idx]
plot_multiple(history, model_name, linecolor, ALPHA, MARKER)
idx += 1

max_epochs = np.amax(all_epochs_completed)
format_histories_plot(max_epochs)
plt.show()

# Let's save the plots
extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
save_dir = f'gdrive/My Drive/Danino_Lab/Patterning_Scans/cheW_umoD_Expts/models_and_histories/plots'
curves_path = save_dir + f'/{date_string}_learning_curves_{curr_date}.svg'
fig.savefig(curves_path, format='svg', bbox_inches=extent.expanded(2.0, 2.0))